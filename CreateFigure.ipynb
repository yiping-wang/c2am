{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import voc12.dataloader\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from misc import pyutils, torchutils\n",
    "from net.resnet50_cam import CAM, Net, ReCAM    \n",
    "from misc import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = '/Users/Andy/Projects/c2am/voc12/train_aug.txt'\n",
    "voc12_root = '/Users/Andy/Projects/dataset/VOCdevkit/VOC2012'\n",
    "baseline_cam_weight_path = '/Users/Andy/Projects/resnet50_baseline_512.pth'\n",
    "\n",
    "cls_dataset = voc12.dataloader.VOC12ClassificationDataset(train_list, voc12_root=voc12_root,\n",
    "                                                            resize_long=(320, 640), hor_flip=True,\n",
    "                                                            crop_size=512, crop_method=\"random\")\n",
    "cls_data_loader = DataLoader(cls_dataset,\n",
    "                               batch_size=1,\n",
    "                               shuffle=False,\n",
    "                               num_workers=0)\n",
    "\n",
    "\n",
    "cam_dataset = voc12.dataloader.VOC12ClassificationDatasetMSF(train_list,\n",
    "                                                          voc12_root=voc12_root,\n",
    "                                                          scales=(1.0, 0.5, 1.5, 2.0))\n",
    "cam_data_loader = DataLoader(cam_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "cls_model = Net()\n",
    "cam_model = CAM()\n",
    "cls_model.eval()\n",
    "cam_model.eval()\n",
    "cls_model.load_state_dict(torch.load(baseline_cam_weight_path, map_location='cpu'))\n",
    "cam_model.load_state_dict(torch.load(baseline_cam_weight_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 7145/10582 [15:22<09:17,  6.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2235e-08, 2.4940e-06, 1.1918e-07, 3.8905e-07, 1.6577e-04, 2.4210e-07,\n",
      "         4.1109e-06, 1.4293e-04, 4.3902e-05, 1.9703e-07, 2.2379e-06, 2.9050e-01,\n",
      "         1.1265e-06, 8.3566e-08, 6.9488e-01, 2.4513e-05, 1.4147e-07, 2.5782e-05,\n",
      "         2.2290e-07, 1.4211e-02]], grad_fn=<SoftmaxBackward0>)\n",
      "['2010_001099']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10582/10582 [26:47<00:00,  6.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for pack in tqdm(cls_data_loader):\n",
    "    names = pack['name']\n",
    "    imgs = pack['img']\n",
    "    labels = pack['label']\n",
    "    if labels[0][11] and labels[0][14] == 0:\n",
    "        logits, _ = cls_model(imgs)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        if probs[0][14] > 0.5:\n",
    "            print(probs)\n",
    "            print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ea383dfe7108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/c2am/.env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/c2am/.env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_set = {}\n",
    "\n",
    "for pack in data_loader:\n",
    "    label = tuple(*pack['label'].numpy().tolist())\n",
    "    if label not in label_set:\n",
    "        label_set[label] = 0\n",
    "    label_set[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in label_set.items():\n",
    "    if k[5] or k[14]:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_wrong = []\n",
    "\n",
    "for pack in data_loader:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 5, 14]),)\n",
      "person\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "CAT_LIST = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "            'cow', 'diningtable', 'dog', 'horse',\n",
    "            'motorbike', 'person', 'pottedplant',\n",
    "            'sheep', 'sofa', 'train',\n",
    "            'tvmonitor']\n",
    "idx = np.asarray((0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0))\n",
    "print(np.nonzero(idx))\n",
    "print(CAT_LIST[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andy/Projects/front_door_cam/.env/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "for pack in data_loader:\n",
    "    label = pack['label'].numpy().tolist()[0]\n",
    "    size = pack['size']\n",
    "    if label[5] or label[14]:\n",
    "        with torch.no_grad():\n",
    "            strided_up_size = imutils.get_strided_up_size(size, 16)\n",
    "            baseline_outputs = [model_baseline(img[0]) for img in pack['img']]\n",
    "            baseline_highres_cam = [F.interpolate(torch.unsqueeze(\n",
    "                        o, 1), strided_up_size, mode='bilinear', align_corners=False) for o in baseline_outputs]\n",
    "            baseline_highres_cam = torch.sum(torch.stack(baseline_highres_cam, 0), 0)[\n",
    "                        :, 0, :size[0], :size[1]]\n",
    "            valid_cat = torch.nonzero(pack['label'][0])[:, 0]\n",
    "            baseline_highres_cam /= F.adaptive_max_pool2d(baseline_highres_cam, (1, 1)) + 1e-5\n",
    "\n",
    "        w = size[0].item()\n",
    "        h = size[1].item()\n",
    "        fig = plt.figure(figsize=(192.0,108.0))\n",
    "        columns = 20 + 1\n",
    "        rows = 1\n",
    "        n = 20\n",
    "        for i in range(1, n +1):\n",
    "            img = baseline_highres_cam[i-1]\n",
    "            img = img.unsqueeze(0).unsqueeze(0)\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(img.numpy().squeeze())\n",
    "            plt.title(CAT_LIST[i-1])\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(Image.open(os.path.join(voc12_root, 'JPEGImages') + '/' + pack['name'][0] + '.jpg'))\n",
    "        plt.title(pack['name'][0])\n",
    "        fig.savefig('../cam_vis/{}.png'.format(pack['name'][0]), dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
