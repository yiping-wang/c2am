{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import voc12.dataloader\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from misc import pyutils, torchutils, imutils\n",
    "from net.resnet50_cam import Net, CAM\n",
    "from torch import nn\n",
    "from torchvision.transforms import transforms\n",
    "from voc12.dataloader import get_img_path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = '/Users/Andy/Projects/front_door_cam/voc12/val.txt'\n",
    "voc12_root = '/Users/Andy/Projects/dataset/VOCdevkit/VOC2012'\n",
    "\n",
    "train_dataset = voc12.dataloader.VOC12ClassificationDataset(train_list, voc12_root=voc12_root,\n",
    "                                                            resize_long=(160, 320), hor_flip=True,\n",
    "                                                            crop_size=256, crop_method=\"random\")\n",
    "train_data_loader = DataLoader(train_dataset,\n",
    "                               batch_size=2,\n",
    "                               shuffle=False,\n",
    "                               num_workers=0,\n",
    "                               pin_memory=True,\n",
    "                               drop_last=True)\n",
    "\n",
    "\n",
    "# data_iter = iter(train_data_loader)\n",
    "# pack = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = Net()\n",
    "# m.load_state_dict(torch.load(os.path.join('/Users/Andy/Projects/resnet50_frontdoor_styleintervention.pth'), map_location='cpu'), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(names, voc12_root):\n",
    "    w = 256\n",
    "    h = 256\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    columns = 4\n",
    "    rows = 4\n",
    "    for i in range(1, columns * rows +1):\n",
    "        im = Image.open(get_img_path(names[i-1], voc12_root)).convert('RGB')\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(im)\n",
    "        plt.title(names[i-1])\n",
    "    plt.show()\n",
    "    \n",
    "def plot_prob(logits, labels):\n",
    "    # plot\n",
    "    x = np.arange(20)\n",
    "    yp = F.softmax(logits, dim=1)\n",
    "    n = logits.shape[0]\n",
    "    columns = 4\n",
    "    rows = 4\n",
    "    index = 0\n",
    "    fig, ax = plt.subplots(columns, rows, figsize=(16, 16))\n",
    "    for i in np.arange(columns):\n",
    "        for j in np.arange(rows):\n",
    "            y = yp[index].squeeze().detach().numpy()  \n",
    "            label = labels[index].numpy()\n",
    "            color = np.asarray(['blue' for _ in range(20)])\n",
    "            color[label == 1] = 'red'\n",
    "            color = color.tolist()\n",
    "            ax[i][j].bar(x, y, width=1, edgecolor=\"white\", linewidth=0.7, color=color)\n",
    "            ax[i][j].set(xlim=(0, 1), xticks=np.arange(20),\n",
    "                   ylim=(0, 1))\n",
    "            index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = pack['img']\n",
    "# print(pack.keys())\n",
    "# names = pack['name']\n",
    "# print(imgs.shape)\n",
    "# labels = pack['label']\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_batch(names, voc12_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(imgs.shape)\n",
    "# logits = m(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_prob(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect CAM\n",
    "\n",
    "# val_list = '/Users/Andy/Projects/front_door_cam/voc12/val.txt'\n",
    "# voc12_root = '/Users/Andy/Projects/dataset/VOCdevkit/VOC2012'\n",
    "# frontdoor_cam_weight_path = '/Users/Andy/Projects/resnet50_frontdoor_styleintervention.pth'\n",
    "\n",
    "# val_dataset = voc12.dataloader.VOC12ClassificationDatasetMSF(val_list,\n",
    "#                                                           voc12_root=voc12_root,\n",
    "#                                                           scales=(1.0, 0.5, 1.5, 2.0))\n",
    "# data_loader = DataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "# model_frontdoor = CAM()\n",
    "# model_frontdoor.eval()\n",
    "# model_frontdoor.load_state_dict(torch.load(frontdoor_cam_weight_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iter = iter(data_loader)\n",
    "# pack = next(data_iter)\n",
    "# pack = next(data_iter)\n",
    "# pack = next(data_iter)\n",
    "# pack = next(data_iter)\n",
    "# pack = next(data_iter)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     img_name = pack['name'][0]\n",
    "#     imgs = pack['img']\n",
    "#     label = pack['label'][0]\n",
    "#     size = pack['size']\n",
    "\n",
    "#     strided_up_size = imutils.get_strided_up_size(size, 16)\n",
    "\n",
    "#     frontdoor_outputs = [model_frontdoor(img[0]) for img in pack['img']]\n",
    "    \n",
    "#     frontdoor_highres_cam = [F.interpolate(torch.unsqueeze(\n",
    "#                 o, 1), strided_up_size, mode='bilinear', align_corners=False) for o in frontdoor_outputs]\n",
    "#     frontdoor_highres_cam = torch.sum(torch.stack(frontdoor_highres_cam, 0), 0)[\n",
    "#                 :, 0, :size[0], :size[1]]\n",
    "\n",
    "\n",
    "#     valid_cat = torch.nonzero(label)[:, 0]\n",
    "\n",
    "#     frontdoor_highres_cam = frontdoor_highres_cam[valid_cat]\n",
    "#     frontdoor_highres_cam /= F.adaptive_max_pool2d(frontdoor_highres_cam, (1, 1)) + 1e-5\n",
    "    \n",
    "\n",
    "# print(frontdoor_highres_cam.min(), frontdoor_highres_cam.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.open(os.path.join(voc12_root, 'JPEGImages', '2007_000129' + '.jpg'))\n",
    "\n",
    "# fig = plt.figure(figsize=(18,18))\n",
    "# ax1 = fig.add_subplot(331)\n",
    "# plt.title('Image')\n",
    "# ax1.imshow(im)\n",
    "# ax2 = fig.add_subplot(332)\n",
    "# plt.title('Baseline CAM - Bicycle')\n",
    "# ax2.imshow(frontdoor_highres_cam[0].squeeze())\n",
    "# ax3 = fig.add_subplot(333)\n",
    "# plt.title('Baseline CAM - Person')\n",
    "# ax3.imshow(frontdoor_highres_cam[1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import resnet50\n",
    "\n",
    "class NetDualHeads(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDualHeads, self).__init__()\n",
    "\n",
    "        self.resnet50 = resnet50.resnet50(\n",
    "            pretrained=True, strides=(2, 2, 2, 1))\n",
    "        self.stage1 = nn.Sequential(self.resnet50.conv1, self.resnet50.bn1, self.resnet50.relu, self.resnet50.maxpool,\n",
    "                                    self.resnet50.layer1)\n",
    "        self.stage2 = nn.Sequential(self.resnet50.layer2)\n",
    "        self.stage3 = nn.Sequential(self.resnet50.layer3)\n",
    "        self.stage4 = nn.Sequential(self.resnet50.layer4)\n",
    "\n",
    "        self.classifier = nn.Conv2d(2048, 20, 1, bias=False)\n",
    "\n",
    "        self.backbone = nn.ModuleList(\n",
    "            [self.stage1, self.stage2, self.stage3, self.stage4])\n",
    "        self.newly_added = nn.ModuleList([self.classifier])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x).detach()\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        logit = torchutils.gap2d(x, keepdims=True)\n",
    "        logit = self.classifier(logit)\n",
    "        logit = logit.view(-1, 20)\n",
    "\n",
    "        cam = F.conv2d(x, self.classifier.weight)\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam / (F.adaptive_max_pool2d(cam, (1, 1)) + 1e-5)\n",
    "        return logit, cam\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        for p in self.resnet50.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.resnet50.bn1.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def trainable_parameters(self):\n",
    "        return (list(self.backbone.parameters()), list(self.newly_added.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = NetDualHeads()\n",
    "cam_learning_rate = 0.1\n",
    "cam_weight_decay = 0.00001\n",
    "max_step = (len(train_dataset) // 2) * 5\n",
    "\n",
    "param_groups = dm.trainable_parameters()\n",
    "optimizer = torchutils.PolyOptimizer([\n",
    "    {'params': param_groups[0], 'lr': cam_learning_rate,\n",
    "        'weight_decay': cam_weight_decay},\n",
    "    {'params': param_groups[1], 'lr': 10 * cam_learning_rate,\n",
    "        'weight_decay': cam_weight_decay},\n",
    "], lr=cam_learning_rate, weight_decay=cam_weight_decay, max_step=max_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3012, -0.4897,  0.2245, -0.1433, -0.0802, -0.2322, -0.1092,  0.2457,\n",
      "         -0.0144, -0.1537,  0.0930,  0.0390, -0.1748, -0.2095,  0.2227,  0.0169,\n",
      "          0.2915,  0.1886,  0.0763,  0.0680],\n",
      "        [ 0.2819, -0.2773,  0.1371,  0.0645,  0.0822, -0.2463, -0.0321,  0.3612,\n",
      "          0.2624, -0.0352,  0.1792,  0.2341, -0.1058, -0.2067,  0.2073, -0.0690,\n",
      "          0.2885,  0.3736, -0.1742,  0.0230]], grad_fn=<ViewBackward0>)\n",
      "1.4792520999908447\n",
      "tensor([[ -1.5550,  -4.7350,  -7.1796,  -7.2491,  -6.9166,  -5.7463,  -6.0006,\n",
      "          -7.7796,  -7.2868,  -6.7854,  -7.6204,  -8.2299,  -6.5619,  -5.9921,\n",
      "          -6.8317,  -7.2264,  -7.9391,  -7.6543,   0.2161,  -6.8037],\n",
      "        [ -2.8537,  -7.3158, -11.2342, -10.4867, -10.6095,  -8.8932,  -9.4327,\n",
      "         -12.0603, -11.0759, -10.4229, -11.5169, -12.4418,  -9.7913,  -8.6733,\n",
      "         -10.2539, -10.9034, -11.9521, -11.6169,   1.0837, -10.6544]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "0.9065588712692261\n",
      "tensor([[-1.8312, -3.4454, -5.1538, -1.9587, -4.8504, -4.1606, -4.3760, -5.5704,\n",
      "         -5.0072, -4.6146, -5.2416, -5.9000, -4.2877, -3.9958, -4.8033, -4.9447,\n",
      "         -5.4181, -5.0944, -0.1206, -4.6787],\n",
      "        [-1.4673, -2.6978, -3.8932, -1.4417, -3.8057, -3.2225, -3.2821, -4.1903,\n",
      "         -3.9431, -3.7035, -4.0791, -4.6126, -3.4728, -3.1302, -3.7940, -3.8027,\n",
      "         -4.2807, -4.0300, -0.1419, -3.7732]], grad_fn=<ViewBackward0>)\n",
      "1.073256015777588\n",
      "tensor([[-1.4965, -0.3737, -3.0347, -1.5518, -2.8036, -2.5341, -2.5900, -3.1868,\n",
      "         -2.8690, -2.6348, -3.1122, -3.3657, -2.5467, -2.5634, -0.9974, -2.7849,\n",
      "         -1.8147, -2.9352, -1.9871, -2.7604],\n",
      "        [-1.1049, -0.3044, -2.1446, -0.9718, -2.1247, -1.8107, -2.0222, -2.3103,\n",
      "         -2.1259, -1.9239, -2.2199, -2.5594, -1.8224, -1.9018, -0.8032, -2.0679,\n",
      "         -1.3138, -2.2263, -1.5120, -1.9705]], grad_fn=<ViewBackward0>)\n",
      "0.9332073330879211\n",
      "tensor([[-2.5994, -2.4518, -3.8724, -2.3692, -3.8264, -3.2757, -3.4055, -4.0912,\n",
      "         -3.8999, -3.5990, -4.0898, -4.4147, -3.6186, -3.3027, -1.4472, -3.8515,\n",
      "         -2.8323, -3.9755, -2.5526, -2.3643],\n",
      "        [-2.3986, -2.6859, -3.8353, -2.4172, -3.7465, -3.2974, -3.5168, -3.8628,\n",
      "         -3.8607, -3.4839, -3.9023, -4.3915, -3.4829, -3.4159, -0.7995, -3.7444,\n",
      "         -2.8144, -3.7164, -2.6180, -1.6827]], grad_fn=<ViewBackward0>)\n",
      "0.952041506767273\n",
      "tensor([[-1.9126, -2.1646, -2.6027, -1.8206, -0.8323, -2.2881, -2.3342, -2.6421,\n",
      "         -2.5084, -2.4071, -2.5959, -2.8062, -1.2150, -2.4805,  0.6219, -2.5223,\n",
      "         -1.8556, -2.4753, -2.4046, -1.1533],\n",
      "        [-2.5271, -2.4907, -3.1622, -2.3184, -1.7299, -2.8202, -2.9818, -3.5083,\n",
      "         -3.3289, -3.0561, -3.4506, -3.6486, -1.4140, -2.9314, -0.3078, -3.1773,\n",
      "         -2.5009, -3.4790, -2.5679, -2.1822]], grad_fn=<ViewBackward0>)\n",
      "1.0351347923278809\n",
      "tensor([[-2.9277, -2.7740, -3.9862, -2.6969, -2.9748, -3.4044, -3.4263, -4.1685,\n",
      "         -2.9153, -2.3573, -4.1072, -4.4290, -2.5463, -3.4333, -2.3271, -3.7929,\n",
      "         -3.2800, -2.9474, -2.6625, -3.2017],\n",
      "        [-2.6139, -2.8620, -3.8735, -2.6953, -2.8097, -3.3496, -3.2941, -3.8757,\n",
      "         -2.8624, -2.2825, -3.8100, -4.2484, -2.3162, -3.2578, -2.1319, -3.6486,\n",
      "         -3.2358, -2.6741, -2.8168, -2.7306]], grad_fn=<ViewBackward0>)\n",
      "0.9508811235427856\n",
      "tensor([[-1.8258, -1.9128, -2.1782, -0.9120, -1.5358, -1.9900, -1.1218, -2.2984,\n",
      "         -1.2721, -0.4919, -2.1924, -2.3514, -1.5444, -2.0865, -1.1674, -2.1369,\n",
      "         -1.8246, -1.3081, -1.9806, -1.4492],\n",
      "        [-2.0254, -2.0553, -2.6991, -0.9580, -2.0715, -2.4415, -1.4552, -2.8782,\n",
      "         -1.9157, -0.7000, -2.7898, -3.0300, -1.9790, -2.5082, -1.6067, -2.6071,\n",
      "         -2.3393, -2.0882, -2.1475, -2.0289]], grad_fn=<ViewBackward0>)\n",
      "0.9821045398712158\n",
      "tensor([[-3.0585, -1.9752, -4.0482, -2.0549, -2.5310, -3.4987, -2.6894, -4.3594,\n",
      "         -3.4230, -2.4096, -4.2162, -4.4223, -3.1111, -3.7207, -3.0148, -3.9316,\n",
      "         -3.7213, -3.5924, -2.6932, -2.8819],\n",
      "        [-3.5129, -2.3683, -5.0671, -2.5567, -3.2106, -4.3077, -3.3853, -5.3602,\n",
      "         -4.1937, -3.1114, -5.1488, -5.3536, -3.8428, -4.4259, -3.5474, -4.8554,\n",
      "         -4.3289, -4.4124, -2.8614, -3.6595]], grad_fn=<ViewBackward0>)\n",
      "0.9444892406463623\n",
      "tensor([[-2.7184e+00, -2.1517e+00, -3.7387e+00, -2.3526e+00, -2.2527e+00,\n",
      "         -3.2783e+00, -2.6855e+00, -3.8140e+00, -3.0633e+00, -2.5150e+00,\n",
      "         -3.7429e+00, -3.9474e+00, -2.9693e+00, -3.2762e+00, -1.4997e+00,\n",
      "         -3.6360e+00, -3.2326e+00, -3.1099e+00, -3.4806e-03, -2.5294e+00],\n",
      "        [-3.0227e+00, -2.2510e+00, -4.0652e+00, -2.5436e+00, -2.7645e+00,\n",
      "         -3.5306e+00, -2.9606e+00, -4.2346e+00, -3.5102e+00, -2.9030e+00,\n",
      "         -4.1357e+00, -4.3268e+00, -3.0777e+00, -3.5000e+00, -1.6806e+00,\n",
      "         -3.8760e+00, -3.5469e+00, -3.6367e+00,  2.5518e-01, -2.7820e+00]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "1.1931507587432861\n",
      "tensor([[-1.6037, -1.2707, -1.3582, -1.0175, -0.5041, -1.0269, -0.4911, -1.4204,\n",
      "         -0.2479, -0.5715, -1.3668, -1.4640, -0.9981, -1.4423, -0.5438, -0.9843,\n",
      "         -1.1312, -0.2731, -1.3408, -0.2177],\n",
      "        [-1.5354, -1.1857, -1.3362, -1.0181, -0.4657, -1.0001, -0.4735, -1.4192,\n",
      "         -0.1734, -0.6885, -1.3206, -1.4406, -1.0462, -1.4664, -0.4486, -0.9261,\n",
      "         -1.2226, -0.1610, -1.3023, -0.1652]], grad_fn=<ViewBackward0>)\n",
      "1.1327704191207886\n",
      "tensor([[-4.2751, -3.5635, -4.5243, -3.3768, -2.7066, -2.2636, -1.4454, -4.5693,\n",
      "         -4.3134, -2.9273, -4.6184, -4.8025, -3.5903, -4.3886, -1.0697, -3.6159,\n",
      "         -2.8236, -3.7777, -3.2695, -3.6186],\n",
      "        [-4.2526, -3.5394, -4.4901, -3.1361, -2.9503, -2.2890, -1.2442, -4.6484,\n",
      "         -4.5682, -2.7461, -4.6363, -4.8174, -3.4788, -4.3829, -1.2437, -3.8112,\n",
      "         -2.7221, -3.9057, -3.4251, -3.7341]], grad_fn=<ViewBackward0>)\n",
      "1.0739362239837646\n",
      "tensor([[-2.3756, -1.9663, -2.5067, -1.9259, -0.2299, -1.3937, -1.3943, -2.5196,\n",
      "         -2.5622, -1.8974, -0.8607, -2.7218, -0.2288, -2.5240,  2.1388, -2.2010,\n",
      "         -1.7630, -2.4176, -1.9585, -2.4268],\n",
      "        [-2.3462, -2.0188, -2.2867, -1.9822,  0.1239, -1.2440, -1.3312, -2.4025,\n",
      "         -2.3803, -1.8957, -0.6020, -2.4651, -0.2201, -2.4453,  2.5379, -2.0225,\n",
      "         -1.5309, -2.0342, -2.1166, -2.2652]], grad_fn=<ViewBackward0>)\n",
      "1.0681536197662354\n",
      "tensor([[-2.9956, -2.6748, -3.2182, -2.6299, -3.3028, -2.2579, -2.2730, -3.3690,\n",
      "         -1.3168, -2.6178, -2.2086, -3.2967, -0.6014, -3.1374,  0.9215, -2.7618,\n",
      "         -2.5263, -1.1511, -2.6408, -3.0926],\n",
      "        [-2.5144, -2.1590, -2.7521, -2.0797, -3.0506, -1.9320, -1.8351, -2.9067,\n",
      "         -1.2921, -2.3091, -2.0451, -2.9041, -0.6934, -2.7802,  0.6585, -2.4760,\n",
      "         -2.2439, -1.3075, -2.1474, -2.6739]], grad_fn=<ViewBackward0>)\n",
      "1.0136222839355469\n",
      "tensor([[-3.2494, -2.8439, -3.7823, -1.7274, -3.3409, -2.7117, -2.7279, -3.9513,\n",
      "         -1.0543, -3.0550, -1.9146, -4.0170, -2.3672, -3.6517, -1.7756, -3.1957,\n",
      "         -3.3974, -2.3626, -2.4440, -3.5257],\n",
      "        [-2.5185, -2.3351, -3.0257, -1.0258, -3.1024, -2.2451, -2.2588, -3.1897,\n",
      "         -0.7496, -2.6291, -1.4089, -3.1837, -2.0277, -2.9813, -1.6119, -2.7121,\n",
      "         -2.5906, -2.0241, -2.2429, -2.9317]], grad_fn=<ViewBackward0>)\n",
      "0.9465194940567017\n",
      "tensor([[-4.4494, -3.9037, -5.0473, -1.6905, -4.6680, -3.9113, -3.6604, -5.2317,\n",
      "         -3.2078, -3.9039, -1.5618, -5.5115, -2.6739, -4.8106,  0.4361, -4.4491,\n",
      "         -4.2918, -4.0464, -3.1897, -4.9608],\n",
      "        [-4.0455, -3.6810, -4.6015, -1.8615, -3.8120, -3.4548, -3.4969, -4.7160,\n",
      "         -2.2341, -3.7867, -0.6941, -4.7986, -2.6937, -4.2987,  1.0298, -3.8815,\n",
      "         -3.9661, -3.1061, -3.3662, -4.2084]], grad_fn=<ViewBackward0>)\n",
      "0.9723355174064636\n",
      "tensor([[-2.7525, -2.6329, -3.1285, -1.1835, -1.6213, -2.4326, -2.4559, -3.2508,\n",
      "         -1.5737, -2.7467, -1.2891, -3.3119, -2.3510, -3.0779,  0.1711, -2.7615,\n",
      "         -1.4778, -2.1094, -2.5374, -2.9095],\n",
      "        [-3.0773, -2.9548, -3.4056, -1.9348, -1.2991, -2.6312, -2.6047, -3.5305,\n",
      "         -1.6756, -2.9073, -1.4086, -3.6169, -2.5278, -3.3678,  0.3393, -2.8637,\n",
      "         -1.9680, -2.1065, -2.7086, -3.0236]], grad_fn=<ViewBackward0>)\n",
      "1.0151149034500122\n",
      "tensor([[-2.8023, -2.5794, -3.2220, -1.7759, -1.8201, -2.6065, -2.5905, -3.3459,\n",
      "         -2.1857, -2.6552, -1.9308, -3.3854, -2.4243, -3.1352, -0.0696, -1.9844,\n",
      "         -1.8729, -1.5250, -2.5693, -1.9571],\n",
      "        [-3.3836, -3.0596, -3.8977, -2.5332, -1.9748, -3.0304, -2.9409, -3.9505,\n",
      "         -2.6462, -3.0500, -2.4161, -4.1555, -2.7247, -3.6284,  0.0215, -2.3996,\n",
      "         -2.4919, -2.0874, -2.5775, -2.3001]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8850836157798767\n",
      "tensor([[-3.2011, -3.1275, -4.1616, -2.2485, -2.7825, -3.1791, -3.0107, -4.2052,\n",
      "         -3.2742, -3.5128, -3.0798, -3.5081, -3.2582, -3.9368, -0.6676, -2.8047,\n",
      "         -2.9332, -2.6997, -2.6491, -3.0113],\n",
      "        [-3.1891, -2.9884, -4.1125, -2.1760, -2.8576, -3.3662, -3.2004, -4.2962,\n",
      "         -3.3688, -3.4878, -3.2615, -3.2433, -3.3620, -3.9662, -0.9450, -2.8788,\n",
      "         -2.7738, -2.7974, -2.7448, -3.1008]], grad_fn=<ViewBackward0>)\n",
      "0.9367886781692505\n",
      "tensor([[-2.3738, -3.0518, -2.7228, -2.2301, -2.9289, -3.1567, -3.0016, -3.9447,\n",
      "         -3.0218, -3.1254, -2.6739, -3.1459, -2.7484, -3.5706, -1.6136, -2.7684,\n",
      "         -2.2427, -2.6710, -2.9105, -2.9931],\n",
      "        [-1.9819, -2.5809, -2.2895, -1.7914, -2.5668, -2.6864, -2.6275, -3.4209,\n",
      "         -2.4898, -2.8834, -2.2370, -2.7016, -2.4415, -3.1353, -1.0104, -2.3479,\n",
      "         -2.0528, -2.0858, -2.6868, -2.4761]], grad_fn=<ViewBackward0>)\n",
      "0.9402510523796082\n",
      "tensor([[-1.9302, -1.8311, -2.4236, -2.0524, -2.3668, -2.6357, -2.5845, -3.3688,\n",
      "         -2.5333, -2.1111, -2.4876, -2.7304, -2.7329, -3.1191, -0.5141, -2.3484,\n",
      "         -2.3421, -2.0928, -2.4892, -2.4891],\n",
      "        [-2.2376, -2.4282, -3.1372, -2.6808, -3.1238, -3.2231, -3.0881, -4.3043,\n",
      "         -3.4867, -2.8414, -3.3762, -3.7462, -3.4227, -3.8840, -1.0927, -3.0908,\n",
      "         -3.3544, -3.1177, -2.6404, -3.2377]], grad_fn=<ViewBackward0>)\n",
      "0.8958350419998169\n",
      "tensor([[-2.3697, -3.8880, -4.8416, -4.6519, -3.6818, -4.9286, -3.7068, -6.1641,\n",
      "         -4.9803, -4.1019, -4.8942, -5.3979, -5.0578, -5.6793, -1.2586, -4.5556,\n",
      "         -4.8689, -4.3988, -4.1528, -4.5407],\n",
      "        [-1.1264, -2.6103, -3.5891, -3.0357, -4.1077, -4.1781, -2.7649, -5.1429,\n",
      "         -4.7503, -3.3359, -4.5421, -4.4678, -4.6073, -4.9101, -2.4603, -3.8909,\n",
      "         -4.1488, -4.0274, -3.3508, -4.2535]], grad_fn=<ViewBackward0>)\n",
      "1.0248225927352905\n",
      "tensor([[-1.7281, -1.9311, -2.0116, -2.1306, -0.5959, -2.1993, -1.7314, -2.5744,\n",
      "         -1.7342, -1.8191, -1.4957, -2.0097, -1.9805, -2.4885,  1.4464, -0.8736,\n",
      "         -1.7386, -1.3794, -2.5602, -1.5947],\n",
      "        [-1.7826, -2.1157, -2.0219, -2.2729, -0.5873, -2.2334, -1.8018, -2.6284,\n",
      "         -1.5594, -1.8880, -1.4296, -1.9897, -2.1437, -2.5473,  1.2613, -0.7881,\n",
      "         -1.8492, -1.2212, -2.7524, -1.5256]], grad_fn=<ViewBackward0>)\n",
      "1.06648850440979\n",
      "tensor([[-2.2482, -2.4592, -2.5570, -2.5164, -1.9272, -2.7358, -2.2886, -3.1786,\n",
      "         -1.2268, -2.2847, -1.2697, -2.5195, -2.5156, -3.0153,  0.2759, -0.8999,\n",
      "         -2.2132, -1.1040, -3.0388, -1.5839],\n",
      "        [-2.3170, -2.5011, -2.8415, -2.5866, -2.0390, -3.0034, -2.4534, -3.4600,\n",
      "         -1.6962, -2.5543, -1.6205, -2.9563, -2.5521, -3.3215,  0.7783, -1.1009,\n",
      "         -2.5704, -1.6147, -3.0695, -1.9070]], grad_fn=<ViewBackward0>)\n",
      "0.8584817051887512\n",
      "tensor([[-3.4432, -4.2510, -4.5976, -4.3075, -3.2110, -4.6123, -3.9284, -5.3943,\n",
      "         -2.9797, -4.2291, -3.1074, -4.6887, -4.5226, -5.0682, -0.1817, -2.4032,\n",
      "         -4.2781, -1.3830, -4.8731, -3.1748],\n",
      "        [-4.7854, -5.4042, -5.4396, -5.7118, -3.4667, -5.8040, -5.1273, -6.4914,\n",
      "         -2.8198, -5.0310, -3.2984, -5.4409, -5.5964, -6.2734,  0.4890, -2.5037,\n",
      "         -5.2967, -0.5351, -6.3123, -3.3950]], grad_fn=<ViewBackward0>)\n",
      "0.9395765662193298\n",
      "tensor([[-1.9504, -3.4978, -4.0683, -3.8098, -0.9806, -4.1425, -3.3845, -4.8712,\n",
      "         -3.2083, -3.3055, -3.1666, -4.3914, -3.2294, -4.3574,  0.3086, -2.5739,\n",
      "         -3.3889, -1.1106, -3.9306, -3.2386],\n",
      "        [-1.1428, -3.0118, -3.3209, -3.1807, -0.3951, -3.4174, -2.9806, -4.0727,\n",
      "         -2.1824, -3.1007, -2.3513, -3.3284, -3.3932, -3.7666, -0.1419, -2.0413,\n",
      "         -3.1516,  0.5051, -3.5968, -2.4869]], grad_fn=<ViewBackward0>)\n",
      "0.9781160354614258\n",
      "tensor([[-2.5181, -2.1598, -3.7301, -3.0335, -2.6631, -3.8298, -3.0271, -4.3972,\n",
      "         -3.3911, -2.6185, -3.1385, -4.0692, -1.7035, -3.9942, -0.3646, -2.8388,\n",
      "         -3.0673, -2.7505, -3.1610, -3.6864],\n",
      "        [-3.1679, -2.5633, -5.0557, -4.2099, -3.1297, -4.8530, -4.0001, -5.8069,\n",
      "         -4.4536, -3.6016, -4.0237, -5.3722, -2.0323, -5.2281,  0.4540, -3.6974,\n",
      "         -4.0937, -3.6549, -4.1397, -4.5845]], grad_fn=<ViewBackward0>)\n",
      "1.0043108463287354\n",
      "tensor([[-1.8067, -0.9159, -2.9820, -2.7838, -1.4756, -2.9221, -2.5440, -3.4091,\n",
      "         -2.2594, -2.6175, -2.2643, -2.3484, -2.0236, -3.2737,  1.0395, -1.9966,\n",
      "         -1.8613, -1.2354, -2.9319, -2.2156],\n",
      "        [-1.8012, -1.0706, -3.1536, -3.1448, -1.3593, -3.0978, -2.5946, -3.7314,\n",
      "         -2.8249, -2.8201, -2.5527, -2.6015, -2.0217, -3.5345,  1.5430, -2.0204,\n",
      "         -2.1308, -2.1121, -2.9861, -2.4373]], grad_fn=<ViewBackward0>)\n",
      "1.0763447284698486\n",
      "tensor([[-1.6521, -1.2340, -2.5594, -2.6207, -1.2083, -2.5729, -2.4200, -2.9870,\n",
      "         -0.6078, -2.4100, -1.3136, -2.0166, -1.8066, -2.8281,  1.0134, -1.6506,\n",
      "         -1.9262, -1.1849, -2.5989, -1.1768],\n",
      "        [-1.1554, -0.6918, -1.7921, -1.5084, -1.5961, -1.9163, -1.6037, -2.1255,\n",
      "         -0.7129, -1.6494, -0.9912, -1.2489, -1.4388, -2.0463,  0.1949, -1.4399,\n",
      "         -1.0261, -1.1139, -2.1565, -1.2495]], grad_fn=<ViewBackward0>)\n",
      "0.9742100238800049\n",
      "tensor([[-2.3541, -2.3745, -4.4147, -3.8456, -2.8884, -4.2110, -3.5960, -4.9647,\n",
      "         -1.4916, -4.0951, -3.0205, -3.7487, -3.2000, -4.5468,  0.3385, -3.2501,\n",
      "         -2.6853, -3.2226, -3.9764, -2.3228],\n",
      "        [-3.1653, -2.2626, -4.4344, -4.2528, -3.1810, -4.5986, -4.1544, -5.1051,\n",
      "         -1.1788, -4.0986, -2.6333, -3.4896, -3.3596, -4.8820,  0.5194, -3.4729,\n",
      "         -2.1429, -2.7561, -4.8529, -2.1032]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-cf8b0ec21968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/front_door_cam/.env/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/front_door_cam/.env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pack in train_data_loader:\n",
    "    imgs = pack['img']\n",
    "    labels = pack['label']\n",
    "    logit, cam  = dm(imgs)\n",
    "    cls_loss = F.multilabel_soft_margin_loss(logit, labels)\n",
    "    print(logit)\n",
    "    cam_loss = F.multilabel_soft_margin_loss(torchutils.mean_agg(cam, r=1), labels)\n",
    "    \n",
    "    loss = cls_loss + cam_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
